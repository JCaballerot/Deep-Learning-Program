{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+EAhWsAGm9+pIFCoG8Ugk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCaballerot/Deep_learning_program/blob/main/Topicos_avanzados/Oxford_IIIT_Pet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\"><font size=\"5\">Oxford-IIIT Pet</font></h1>\n",
        "\n"
      ],
      "metadata": {
        "id": "uhlUndyhKLf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este dataset está diseñado específicamente para tareas de clasificación de imágenes y detección de objetos relacionadas con mascotas.\n",
        "\n",
        "\n",
        "---\n",
        "*  Contiene alrededor de 7,400 imágenes de 37 categorías diferentes de mascotas, con un enfoque en razas de perros y gatos.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "38cV8WTHLQPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "  <img src=\"https://production-media.paperswithcode.com/datasets/Oxford-IIIT_Pets-0000000571-4547798f_WG4TMz3.jpg\" width=\"800\" height=\"300\">\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "9WiGtKEsLhNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook proporciona un ejemplo práctico de cómo cargar, preprocesar y modelar el dataset Oxford-IIIT Pet para tareas de clasificación de imágenes utilizando TensorFlow. Este dataset es un conjunto de datos estándar en el dominio del aprendizaje profundo para la clasificación de imágenes de mascotas, con un enfoque particular en diferentes razas de perros y gatos.\n",
        "\n"
      ],
      "metadata": {
        "id": "GQN3SxrihSqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Instalación de dependencias\n"
      ],
      "metadata": {
        "id": "1QcxRvuZhWth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero, nos aseguramos de tener todas las dependencias necesarias instaladas. Esto incluye TensorFlow y TensorFlow Datasets."
      ],
      "metadata": {
        "id": "7vmfZh12hbN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tensorflow-datasets"
      ],
      "metadata": {
        "id": "ziLC2iZJvlXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Principales librerías"
      ],
      "metadata": {
        "id": "EcA6OdEBJGv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de comenzar, importamos las bibliotecas necesarias. TensorFlow se usa para construir y entrenar el modelo, TensorFlow Datasets para cargar el dataset y Matplotlib para la visualización."
      ],
      "metadata": {
        "id": "bBA60vD1hkiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zCW1fEUCJEm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Carga del dataset Oxford-IIIT Pet"
      ],
      "metadata": {
        "id": "3DsTA1n5JL_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset se carga utilizando TensorFlow Datasets, lo que simplifica el proceso de descargar y preparar los datos. Al cargar el dataset, también obtenemos info que contiene metadatos útiles sobre el dataset, como el número de clases y ejemplos.\n",
        "\n"
      ],
      "metadata": {
        "id": "oSoBhxiFhqQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga el conjunto de datos Oxford-IIIT Pet, descargándolo si es necesario\n",
        "ds, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True, split='train', as_supervised=True)\n",
        "\n",
        "# Información del conjunto de datos\n",
        "print(info)\n"
      ],
      "metadata": {
        "id": "R1sm3dl9hyaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Preparación de datos"
      ],
      "metadata": {
        "id": "jJUCX_A8JQrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para una exploración inicial, seleccionamos una muestra de 1000 imágenes. Esto nos permite trabajar con un conjunto de datos más pequeño, facilitando el proceso de desarrollo y prueba del modelo."
      ],
      "metadata": {
        "id": "1_LMEvKuh2LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Para trabajar con una muestra más pequeña, puedes usar la operación take\n",
        "sample_ds = ds.take(1000)  # Toma solo las primeras 100 imágenes\n",
        "\n",
        "# Iterar sobre la muestra del conjunto de datos\n",
        "for image, label in sample_ds:\n",
        "    print(image.shape, label)"
      ],
      "metadata": {
        "id": "Ap_rP18Vvipy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iteramos a través de esta muestra para inspeccionar las dimensiones de las imágenes y sus correspondientes etiquetas."
      ],
      "metadata": {
        "id": "UYq0fIsSh5Qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El preprocesamiento es un paso crucial para asegurar que las imágenes estén en el formato adecuado para entrenar nuestro modelo. Redimensionamos las imágenes a 128x128 y normalizamos los valores de los píxeles a un rango de 0 a 1."
      ],
      "metadata": {
        "id": "V5pLPfB8h7dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (128, 128))\n",
        "    image = image / 255.0  # Normalizar a [0, 1]\n",
        "    return image, label\n",
        "\n",
        "# Cargar el conjunto de datos\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'oxford_iiit_pet:3.*.*',\n",
        "    split=['train', 'test'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "# Preprocesar el conjunto de datos\n",
        "ds_train = ds_train.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "2ep8M23gxwDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos y dividimos el dataset en conjuntos de entrenamiento y prueba, aplicando la función de preprocesamiento a cada imagen.\n",
        "\n"
      ],
      "metadata": {
        "id": "HlMt3EPQh9p0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Arquitectura de la red"
      ],
      "metadata": {
        "id": "D5QfEAVUJlSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestro modelo utiliza una arquitectura convolucional simple con capas de convolución y max pooling, seguida por capas densas para la clasificación final. La última capa tiene una unidad por cada clase en el dataset y utiliza la función de activación softmax.\n",
        "\n"
      ],
      "metadata": {
        "id": "rXMcP0OXiBws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Capa convolucional: 32 filtros de tamaño 3x3, activación ReLU.\n",
        "2. Pooling: Max pooling con una ventana de 2x2.\n",
        "3. Capa convolucional: 64 filtros de tamaño 3x3, activación ReLU.\n",
        "4. Pooling: Max pooling con una ventana de 2x2.\n",
        "5. Flatten: Aplana la salida para convertirla en un vector.\n",
        "6. Densa: Capa densa con 128 unidades, activación ReLU.\n",
        "7. Salida: Capa densa con un número de unidades igual al número de clases en el dataset, activación softmax."
      ],
      "metadata": {
        "id": "Vpc_Q_iVL4nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(ds_info.features['label'].num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xj-z-92tx-4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilamos el modelo especificando el optimizador, la función de pérdida y las métricas. Luego, entrenamos el modelo con los datos de entrenamiento, utilizando los datos de prueba para la validación.\n",
        "\n"
      ],
      "metadata": {
        "id": "66g0YMdSiHid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds_train, validation_data=ds_test, epochs=20)\n"
      ],
      "metadata": {
        "id": "hMB1b-Onx3PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Evaluación y predicción\n",
        "\n"
      ],
      "metadata": {
        "id": "LLnReXUVJspP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar la efectividad de nuestro modelo, realizamos predicciones sobre nuevas imágenes del conjunto de prueba y comparamos los resultados con las etiquetas reales. Esto nos proporciona una buena indicación de cómo el modelo podría comportarse en datos no vistos previamente.\n"
      ],
      "metadata": {
        "id": "04IXCIxbiPie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Asumiendo que `model` es tu modelo entrenado y `ds_test` es tu conjunto de datos de prueba preprocesado\n",
        "\n",
        "# Tomar una sola imagen y etiqueta del conjunto de datos de prueba\n",
        "for image, true_label in ds_test.unbatch().take(3):\n",
        "    # Expandir las dimensiones de la imagen para que sea `(1, height, width, channels)`\n",
        "    img_array = tf.expand_dims(image, 0)\n",
        "\n",
        "    # Realizar la predicción\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    # Tomar la clase predicha y la confianza (probabilidad)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    confidence = np.max(predictions[0])\n",
        "\n",
        "    # Obtener la etiqueta de clase real y predicha para mostrar\n",
        "    class_names = ds_info.features['label'].names\n",
        "    true_label_name = class_names[true_label]\n",
        "    predicted_class_name = class_names[predicted_class]\n",
        "\n",
        "    # Mostrar la imagen, la clase predicha y la confianza\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'Actual: {true_label_name}, Predicted: {predicted_class_name} \\n Confidence: {confidence*100:.2f}%')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FOp6R3kPyIgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(ds_test)\n",
        "print(f'Total accuracy: {accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVYt5sqEKItQ",
        "outputId": "08e10d41-1068-4c87-e68b-e11cdcb47f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 37s 2s/step - loss: 7.4271 - accuracy: 0.1150\n",
            "Total accuracy: 11.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(ds_train)\n",
        "print(f'Total accuracy: {accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElmBns7GMPAT",
        "outputId": "4d146c13-3ca4-415e-aef0-85e381b3e933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 40s 2s/step - loss: 0.0499 - accuracy: 0.9943\n",
            "Total accuracy: 99.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Experimentación con una arquitectura alternativa (Alexnet)"
      ],
      "metadata": {
        "id": "zSfQZtiDMRUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como paso adicional, experimentamos con una arquitectura de modelo inspirada en AlexNet, adaptada para nuestro problema específico. Esto ilustra cómo diferentes arquitecturas pueden influir en el rendimiento del modelo."
      ],
      "metadata": {
        "id": "Pvw3kO3Jia95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_like_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(ds_info.features['label'].num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "alexnet_like_model.compile(optimizer='adam',\n",
        "                           loss='sparse_categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "alexnet_like_model.summary()"
      ],
      "metadata": {
        "id": "dRPNyHq0MHf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este laboratorio demuestra el proceso completo de cargar, preparar y entrenar un modelo de clasificación de imágenes utilizando el conjunto de datos Oxford-IIIT Pet.  La arquitectura del modelo se basa en capas convolucionales y de pooling para extraer características, y capas densas para la clasificación. Se entrenan dos modelos diferentes, uno siguiendo una estructura secuencial básica y otro inspirado en AlexNet, mostrando la flexibilidad y el poder de TensorFlow para el manejo y análisis de imágenes."
      ],
      "metadata": {
        "id": "Zhb-9vmSjDhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Gracias por completar este laboratorio!"
      ],
      "metadata": {
        "id": "ggboS3srMaYs"
      }
    }
  ]
}