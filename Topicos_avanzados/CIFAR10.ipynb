{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnv58Zbpn9/eUl3ozOxuYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCaballerot/Deep_learning_program/blob/main/Topicos_avanzados/CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\"><font size=\"5\">CIFAR10</font></h1>\n"
      ],
      "metadata": {
        "id": "gijkBA8bDfiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "  <img src=\"https://symjax.readthedocs.io/en/latest/_images/sphx_glr_plot_cifar10_001.svg\" width=\"800\" height=\"300\">\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "6KS2LHNcgqwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este laboratorio se enfoca en la construcción, entrenamiento y optimización de un modelo de red neuronal convolucional (CNN) para clasificar imágenes del conjunto de datos CIFAR10, que consiste en 60,000 imágenes a color de 32x32 distribuidas en 10 clases diferentes."
      ],
      "metadata": {
        "id": "LYvYpU9ODzbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Instalación de dependencias\n"
      ],
      "metadata": {
        "id": "0ELb0bhGD32h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero, instalamos scikeras, que es una interfaz de Scikit-learn para Keras, permitiéndonos usar herramientas de Scikit-learn como GridSearchCV para optimizar nuestros modelos de Keras."
      ],
      "metadata": {
        "id": "dh2PcfxCD9Kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install scikeras"
      ],
      "metadata": {
        "id": "odm14iDiBiuK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "BhWgo16PEZzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Importación de librerías necesarias"
      ],
      "metadata": {
        "id": "0RtX_iRVEDGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí importamos todas las librerías necesarias para nuestro laboratorio, incluyendo TensorFlow, Keras para la construcción del modelo, y Scikit-learn para la optimización de hiperparámetros."
      ],
      "metadata": {
        "id": "7Vfgh_5uEN1q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0VNq5Twf_v9n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CWQr93aTEbFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Definición del modelo\n"
      ],
      "metadata": {
        "id": "xyu3Sl4cERxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección, definimos la arquitectura de nuestra red neuronal convolucional (CNN), especificando capas convolucionales, capas de pooling, y capas densas para la clasificación. También configuramos dinámicamente el optimizador, la tasa de aprendizaje y la función de pérdida."
      ],
      "metadata": {
        "id": "vIdoTLEmEXJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model(learning_rate=0.01, optimizer='adam', loss='sparse_categorical_crossentropy'):\n",
        "\n",
        "    model = Sequential([\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Dropout(0.25),  # Agregar Dropout después de la capa de MaxPooling\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),  # Agregar Dropout antes de la capa final\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    optimizer_choices = {\n",
        "        'adam': Adam(learning_rate=learning_rate),\n",
        "        'sgd': keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "        'rmsprop': keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    }\n",
        "\n",
        "    model.compile(optimizer=optimizer_choices[optimizer],\n",
        "                  loss=loss,\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "qF2X6sv0AI85"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Preprocesamiento de datos\n"
      ],
      "metadata": {
        "id": "iNixfuB1Een_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos y preprocesamos el conjunto de datos CIFAR10, normalizando las imágenes y convirtiendo las etiquetas a formato one-hot para su uso con la función de pérdida categorical_crossentropy."
      ],
      "metadata": {
        "id": "pzyOAuCPEidj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "N74Cv7DfEmR0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKhXqDMZF6ju",
        "outputId": "c5769e8d-cf0b-445d-b7c4-4ade02bdf0f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestrear 2000 datos aleatoriamente de cada conjunto (entrenamiento y prueba)\n",
        "indices_train = np.random.choice(range(x_train.shape[0]), size = 1000, replace=False)\n",
        "indices_test = np.random.choice(range(x_test.shape[0]), size = 1000, replace=False)\n",
        "\n",
        "x_train_sampled = x_train[indices_train]\n",
        "y_train_sampled = y_train[indices_train]\n",
        "\n",
        "x_test_sampled = x_test[indices_test]\n",
        "y_test_sampled = y_test[indices_test]"
      ],
      "metadata": {
        "id": "BR4ZU1z-Gr9E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Normalizar los datos\n",
        "x_train_sampled, x_test_sampled = x_train_sampled / 255.0, x_test_sampled / 255.0\n",
        "\n",
        "# Para usar 'categorical_crossentropy', necesitamos etiquetas en formato one-hot\n",
        "y_train_one_hot = to_categorical(y_train_sampled, 10)\n",
        "y_test_one_hot = to_categorical(y_test_sampled, 10)"
      ],
      "metadata": {
        "id": "iRbcEDopAPRu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Configuración de Gridsearch\n"
      ],
      "metadata": {
        "id": "u-GscunYEq-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establecemos una grilla de hiperparámetros para explorar diferentes configuraciones de tasa de aprendizaje, tamaño de lote, optimizadores y funciones de pérdida, y preparamos nuestro modelo para la optimización."
      ],
      "metadata": {
        "id": "EdAe8s2FEzZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'model__learning_rate': [0.001, 0.01, 0.1],\n",
        "    'batch_size': [64, 128, 256],\n",
        "    'model__optimizer': ['adam', 'sgd', 'rmsprop'],  # optimizador\n",
        "    'model__loss': ['sparse_categorical_crossentropy']  # función de pérdida\n",
        "}"
      ],
      "metadata": {
        "id": "t0E8GzX0ARwG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Ejecución de la búsqueda de hiperparámetros y resultados\n"
      ],
      "metadata": {
        "id": "ZS-mvkW6E5X5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, ejecutamos la búsqueda de hiperparámetros utilizando GridSearchCV, entrenando el modelo con diferentes configuraciones y evaluando su rendimiento. Los mejores parámetros se muestran al final, junto con el rendimiento de todas las configuraciones probadas."
      ],
      "metadata": {
        "id": "EJ4yYDYmFAu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn = create_model, epochs = 10, verbose=1)  # Ajusta epochs según necesidad\n",
        "\n",
        "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = 1, cv = 3, verbose = 2)\n"
      ],
      "metadata": {
        "id": "imcKalH3FaJa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usa y_train_one_hot si eliges 'categorical_crossentropy', y_train para 'sparse_categorical_crossentropy'\n",
        "grid_result = grid.fit(x_train_sampled, y_train_sampled)\n"
      ],
      "metadata": {
        "id": "aOyPdNuLFd2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Mejor: %f usando %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds  = grid_result.cv_results_['std_test_score']\n",
        "\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) con: %r\" % (mean, stdev, param))\n"
      ],
      "metadata": {
        "id": "k0jeItjgAVPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LzgTN9pULYAo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asume que grid_result es el resultado de tu GridSearchCV\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "results_df = pd.DataFrame(params)\n",
        "results_df['Mean Accuracy'] = means\n",
        "results_df['Std Deviation'] = stds\n",
        "\n",
        "# Opcionalmente, podrías querer añadir una columna ID para identificar cada configuración\n",
        "results_df['Config ID'] = results_df.index\n",
        "\n",
        "results_df"
      ],
      "metadata": {
        "id": "GbR66YkmLZsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecciona el hiperparámetro para visualizar\n",
        "hyperparam = 'model__optimizer'  # Este es el hiperparámetro de interés\n",
        "\n",
        "# Preparando los datos para el gráfico\n",
        "# Agrupando por el hiperparámetro seleccionado y calculando la media y desviación estándar de la precisión para cada valor\n",
        "grouped = results_df.groupby(hyperparam)['Mean Accuracy'].agg(['mean', 'std']).reset_index()\n",
        "\n",
        "# Graficar los resultados\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(grouped[hyperparam], grouped['mean'], yerr=grouped['std'], color='skyblue', capsize=5)\n",
        "plt.title(f'Impacto de {hyperparam.capitalize()} en la Precisión Media')\n",
        "plt.xlabel(hyperparam.capitalize())\n",
        "plt.ylabel('Precisión Media')\n",
        "plt.xticks(rotation=45)  # Rota las etiquetas si son largas o numerosas\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QmK9CYLXLnu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Conclusión"
      ],
      "metadata": {
        "id": "Lgxk_QKCFooM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este laboratorio, aplicamos técnicas de optimización de hiperparámetros en un modelo de red neuronal convolucional (CNN) para clasificar imágenes del conjunto de datos CIFAR-10. A través del uso de GridSearchCV con KerasClassifier, exploramos combinaciones de hiperparámetros críticos, incluyendo la tasa de aprendizaje, el tamaño de lote, el optimizador y la función de pérdida, buscando la configuración óptima que maximizara la precisión de nuestro modelo.\n",
        "\n",
        "Los resultados obtenidos demuestran que la optimización de hiperparámetros juega un papel crucial en el desempeño de los modelos de aprendizaje profundo. Identificamos la combinación de hiperparámetros que proporcionó la mayor precisión en la clasificación de las imágenes CIFAR-10, lo cual subraya la importancia de un proceso de selección y ajuste meticuloso.\n",
        "\n",
        "Este laboratorio también destaca la potencia y flexibilidad de scikeras y GridSearchCV para integrar modelos de Keras en flujos de trabajo de aprendizaje automático con scikit-learn, facilitando así la experimentación y la optimización de modelos de aprendizaje profundo."
      ],
      "metadata": {
        "id": "WdggEINZFUPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Gracias por completar este laboratorio!"
      ],
      "metadata": {
        "id": "GcNVG7ZTFGva"
      }
    }
  ]
}