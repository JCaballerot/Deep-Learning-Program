{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JCaballerot/Deep_learning_program/blob/main/Deep_learning_program/Deep_learning_program/Modulo_IV/Lab_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8O7Sck2tAAe"
      },
      "source": [
        "<h1 align=\"center\"><font size=\"5\">AUTOENCODERS</font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3S7LKxftAAf"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "Bienvenido a este laboratorio sobre autoencoders.\n",
        "<font size = \"3\"> <strong> En este laboratorio encontrarás una explicación de qué es un autoencoder, cómo funciona y verás una implementación de un autoencoder en TensorFlow.</strong></font>\n",
        "<br>\n",
        "<br>\n",
        "<h2>Tabla de Contenidos</h2>\n",
        "<ol>\n",
        " <li><a href=\"#ref1\">Introducción</a></li>\n",
        " <li><a href=\"#ref2\">Feature Extraction y Dimensionality Reduction</a></li>\n",
        " <li><a href=\"#ref3\">Estructura del Autoencoder</a></li>\n",
        " <li><a href=\"#ref4\">Performance</a></li>\n",
        " <li><a href=\"#ref5\">Entrenamiento: Loss Function</a></li>\n",
        " <li><a href=\"#ref6\">Código</a></li>\n",
        "</ol>\n",
        "</div>\n",
        "<br>\n",
        "Al final de este laboratorio, debería poder crear autoencoders simples y aplicarlos a problemas que implican aprendizaje no supervisado.\n",
        "<br>\n",
        "<p></p>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGthATggtAAg"
      },
      "source": [
        "<a id=\"ref1\"></a>\n",
        "<h2>Introducción</h2>\n",
        "Un autoencoder, también conocido como autoassociator o Diabolo networks, es una red neuronal artificial empleada para recrear la entrada dada.\n",
        "Toma un conjunto de entradas <b>sin etiquetar</b>, las codifica y luego intenta extraer la información más valiosa de ellas.\n",
        "Se utilizan para extracción de características, aprendizaje de modelos generativos de datos, reducción de dimensionalidad y se pueden utilizar para compresión.\n",
        "\n",
        "Un artículo de 2006 llamado <b> <a href=\"https://www.cs.toronto.edu/~hinton/science.pdf\"> Reducción de la dimensionalidad de los datos con redes neuronales </a>, realizado por GE Hinton y RR Salakhutdinov </b>, mostró mejores resultados que años de refinamiento de otros tipos de red, y fue un gran avance en el campo de las redes neuronales, un campo que estuvo \"estancado\" durante 10 años.\n",
        "\n",
        "Ahora, los autoencoders, basados en máquinas restringidas de Boltzmann, se emplean en algunas de las aplicaciones de deep learning más grandes. Son los componentes básicos de Deep Belief Networks (DBN).\n",
        "\n",
        "<center><img src=\"https://ibm.box.com/shared/static/xlkv9v7xzxhjww681dq3h1pydxcm4ktp.png\" style=\"width: 350px;\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBO7mvBHtAAh"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0L-WRZutAAh"
      },
      "source": [
        "<a id=\"ref2\"></a>\n",
        "<h2>Feature Extraction y Dimensionality Reduction</h2>\n",
        "\n",
        "Un ejemplo dado por Nikhil Buduma en KdNuggets (<a href=\"http://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html\"> enlace </a>) dio un Excelente explicación de la utilidad de este tipo de redes neuronales.\n",
        "\n",
        "Digamos que quieres extraer la emoción que siente la persona en una fotografía. Usando la siguiente imagen en escala de grises de 256x256 píxeles como ejemplo:\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/r5knpow4bk2farlvxia71e9jp2f2u126.png\">\n",
        "\n",
        "Pero cuando usamos esta imagen, ¡comenzamos a encontrarnos con un cuello de botella! ¡Porque esta imagen con un tamaño de 256x256 píxeles se corresponde con un vector de entrada de 65536 dimensiones! Si usáramos una imagen producida con cámaras de celular convencionales, que genera imágenes de 4000 x 3000 píxeles, tendríamos 12 millones de dimensiones para analizar.\n",
        "\n",
        "\n",
        "Este cuello de botella se problematiza aún más a medida que aumenta la dificultad de un problema de machine learning a medida que se involucran más dimensiones. Según un estudio de 1982 de CJ Stone (<a href=\"http://www-personal.umich.edu/~jizhu/jizhu/wuke/Stone-AoS82.pdf\"> enlace </a>), el momento de ajustarse a un modelo, es óptimo si:\n",
        "<br><br>\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "<h3><strong>$$m^{-p/(2p+d)}$$</strong></h3>\n",
        "<br>\n",
        "Donde:\n",
        "<br>\n",
        "m: número de datos\n",
        "<br>\n",
        "d: dimensionalidad de los datos\n",
        "<br>\n",
        "p: Parámetros del modelo\n",
        "</div>\n",
        "\n",
        "Como puede ver, ¡aumenta exponencialmente!\n",
        "Volviendo a nuestro ejemplo, no necesitamos utilizar todas las 65.536 dimensiones para clasificar una emoción. Un humano identifica las emociones de acuerdo con una expresión facial específica, algunas <b> características clave </b>, como la forma de la boca y las cejas.\n",
        "\n",
        "<center><img src=\"https://ibm.box.com/shared/static/m8urvuqujkt2vt1ru1fnslzh24pv7hn4.png\" height=\"256\" width=\"256\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZrQBAEetAAi"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxDMHsb0tAAi"
      },
      "source": [
        "<a id=\"ref3\"></a>\n",
        "<h2>Estructura del Autoencoder</h2>\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/no7omt2jhqvv7uuls7ihnzikyl9ysnfp.png\" style=\"width: 400px;\">\n",
        "\n",
        "\n",
        "Un autoencoder se puede dividir en dos partes, el <b> encoder </b> y el <b> decoder </b>.\n",
        "\n",
        "El encoder necesita comprimir la representación de una entrada. En este caso vamos a reducir la dimensión del rostro de nuestro actor, de 2000 dimensiones a solo 30 dimensiones, haciendo pasar los datos por capas de nuestro encoder.\n",
        "\n",
        "El decoder funciona como una red de encoders a la inversa. Funciona para recrear la entrada lo más fielmente posible. Esto juega un papel importante durante el entrenamiento, porque obliga al codificador automático a seleccionar las características más importantes en la representación comprimida.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hptr4j5WtAAj"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpKZzoGCtAAk"
      },
      "source": [
        "<a id=\"ref4\"></a>\n",
        "<h2>Performance</h2>\n",
        "\n",
        "Una vez realizado el entrenamiento, puede utilizar los datos codificados como datos fiables reducidos dimensionalmente, aplicándolos a cualquier problema donde la reducción dimensional parezca apropiada.\n",
        "\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/yt3xyon4g2jyw1w9qup1mvx7cgh28l64.png\">\n",
        "\n",
        "\n",
        "Esta imagen fue extraída del <a href=\"https://www.cs.toronto.edu/~hinton/science.pdf\"> artículo </a> de GE Hinton y RR Salakhutdinov, sobre la reducción bidimensional para 500 dígitos del MNIST, con PCA a la izquierda y autoencoder a la derecha. Podemos ver que el autoencoder nos proporcionó una mejor separación de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMuNY3aPtAAk"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFFewsUNtAAl"
      },
      "source": [
        "<a id=\"ref5\"></a>\n",
        "<h2>Entrenamiento: Loss function</h2>\n",
        "\n",
        "Un autoencoder utiliza la función de pérdida para entrenar adecuadamente la red. La función de pérdida calculará las diferencias entre nuestra producción y los resultados esperados. Después de eso, podemos minimizar este error con el descenso de gradiente. Hay más de un tipo de función de pérdida, depende del tipo de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLzBXt7vtAAm"
      },
      "source": [
        "<h3>Valores Binarios:</h3>\n",
        "$$l(f(x)) = - \\sum_{k} (x_k log(\\hat{x}_k) + (1 - x_k) \\log (1 - \\hat{x}_k) \\ )$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gicteL1tAAn"
      },
      "source": [
        "Para valores binarios, podemos usar una ecuación basada en la suma de la entropía cruzada de Bernoulli.\n",
        "\n",
        "$ x_k $ es una de nuestras entradas y $\\hat{x}_k $ es la salida respectiva.\n",
        "\n",
        "Usamos esta función para que si $ x_k $ es igual a uno, queremos acercar $ \\hat{x}_k$ lo más cerca posible de uno. Lo mismo si $x_k$ es igual a cero.\n",
        "\n",
        "Si el valor es uno, solo necesitamos calcular la primera parte de la fórmula, es decir, $-x_klog(\\hat{x}_k)$. Lo cual resulta simplemente calcular $-log (\\hat{x}_k)$.\n",
        "\n",
        "Y si el valor es cero, necesitamos calcular solo la segunda parte, $(1 - x_k) \\log (1 - \\hat{x}_k) \\ )$ - que resulta ser $log (1 - \\hat{x}_k) $.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VAjvQVYtAAn"
      },
      "source": [
        "<h3>Real values:</h3>\n",
        "$$l(f(x)) = - \\frac{1}{2}\\sum_{k} (\\hat{x}_k- x_k \\ )^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhuUPkCMtAAo"
      },
      "source": [
        "Como la función anterior se comportaría mal con entradas que no sean 0 o 1, podemos usar la suma de diferencias al cuadrado para nuestra función de pérdida. Si usa esta función de pérdida, es necesario que use una función de activación lineal para la capa de salida.\n",
        "\n",
        "Como en el ejemplo anterior, $ x_k $ es una de nuestras entradas y $\\hat{x}_k $ es la salida respectiva, y queremos que nuestra salida sea lo más similar posible a nuestra entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q9Se8wztAAp"
      },
      "source": [
        "<h3>Loss Gradient:</h3>\n",
        "\n",
        "$$\\nabla_{\\hat{a}(x^{(t)})} \\ l( \\ f(x^{(t)}))  = \\hat{x}^{(t)} - x^{(t)} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "367k4gaKtAAp"
      },
      "source": [
        "Usamos el descenso del gradiente para alcanzar el mínimo local de nuestra función $l( \\ f(x^{(t)})$, dando pasos hacia el negativo del gradiente de la función en el punto actual.\n",
        "\n",
        "Nuestra función sobre el gradiente $(\\nabla_{\\hat{a}(x^{(t)})})$ de la pérdida de $l( \\ f(x^{(t)})$ en la preactivación de la capa de salida.\n",
        "\n",
        "En realidad, es una fórmula simple, se hace calculando la diferencia entre nuestra salida $\\hat{x}^{(t)}$ y nuestra entrada $x^{(t)}$.\n",
        "\n",
        "Entonces nuestra red propaga hacia atrás nuestro gradiente $\\nabla_{\\hat{a}(x^{(t)})} \\ l( \\ f(x^{(t)}))$ a través de la red usando <b>backpropagation</b>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcZZ21JRtAAq"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bEzMqUotAAr"
      },
      "source": [
        "<a id=\"ref6\"></a>\n",
        "<h2>Codigo</h2>\n",
        "\n",
        "Para esta parte, analizamos una gran cantidad de código Python 2.7.11. Vamos a utilizar el conjunto de datos MNIST para nuestro ejemplo. Puede encontrar mas detalle del código en <a href=\"https://github.com/aymericdamien\"> aquí </a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZd7czVAtAAt"
      },
      "source": [
        "Llamemos a nuestras librerías y hagamos que los datos MNIST estén disponibles para su uso."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import RMSprop\n"
      ],
      "metadata": {
        "id": "W5AjeZ31QzDf"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# Cargar el conjunto de datos MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "IIlYoRdYOz_K"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar y aplanar los datos\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n"
      ],
      "metadata": {
        "id": "DHA0CxKeO1Qn"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK3rgaQotAAy"
      },
      "source": [
        "Ahora, seteemos los parámetros que va a utilizar nuestra red."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros de la red\n",
        "batch_size = 500\n",
        "training_epochs = 100\n",
        "learning_rate = 0.01\n"
      ],
      "metadata": {
        "id": "Y-YPNWYNQ4_U"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx1HnLRqtAA1"
      },
      "source": [
        "Ahora necesitamos crear nuestro codificador. Para ello vamos a utilizar funciones sigmoides. Las funciones sigmoides ofrecen excelentes resultados con este tipo de red. Esto se debe a que tiene un buen derivado que se adapta bien a la retropropagación. Podemos crear nuestro codificador usando la función sigmoidal como esta:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Capa de entrada\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "# Encoder\n",
        "encoded = Dense(256, activation='sigmoid')(input_img)\n",
        "encoded = Dense(128, activation='sigmoid')(encoded)\n",
        "encoded = Dense(56,  activation='sigmoid')(encoded)\n",
        "# Decoder\n",
        "decoded = Dense(56,  activation='sigmoid')(encoded)\n",
        "decoded = Dense(256, activation='sigmoid')(encoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n"
      ],
      "metadata": {
        "id": "pvFPTV2nRBul"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Autoencoder\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "metadata": {
        "id": "uRBOBjW6RVSj"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_IXCektABB"
      },
      "source": [
        "Construyamos nuestro modelo.\n",
        "En la variable <code> cost </code> tenemos la función de pérdida y en la variable <code> optimizer </code> tenemos nuestro gradiente usado para el backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar modelo\n",
        "autoencoder.compile(optimizer = RMSprop(learning_rate = learning_rate), loss = 'mean_squared_error')\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)\n"
      ],
      "metadata": {
        "id": "sXuS_X78O5R6"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar modelo\n",
        "\n",
        "history = autoencoder.fit(x_train, x_train,\n",
        "                          epochs = training_epochs,\n",
        "                          batch_size = batch_size,\n",
        "                          shuffle = True,\n",
        "                          validation_data = (x_test, x_test),\n",
        "                          callbacks = [early_stopping])\n"
      ],
      "metadata": {
        "id": "lF7WK7OgRZ5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 4))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 5.4559e-04)"
      ],
      "metadata": {
        "id": "ZJXl0chaSu4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar las reconstrucciones\n",
        "examples_to_show = 8\n",
        "decoded_imgs = autoencoder.predict(x_test[:examples_to_show])"
      ],
      "metadata": {
        "id": "uBNQfNbGRZ1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OguhlAsHtABJ"
      },
      "source": [
        "Ahora, apliquemos codificador y decodificador para nuestras pruebas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRA1kkuqtABM"
      },
      "source": [
        "Visualicemos nuestros resultados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las imágenes originales y sus reconstrucciones\n",
        "n = examples_to_show\n",
        "plt.figure(figsize=(10, 2))\n",
        "for i in range(n):\n",
        "    # Original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Reconstrucción\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OzuIIc8LRZvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjTLTAqOtABP"
      },
      "source": [
        "\n",
        "Como puede ver, las reconstrucciones tuvieron éxito. Se puede ver que se agregó algo de ruido a la imagen."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando autoencoders para modelos generativos"
      ],
      "metadata": {
        "id": "_o_NfxtXcdar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar una imagen\n",
        "image_index = 14  # Por ejemplo, elegir la imagen 123 del conjunto de test\n",
        "image = x_test[image_index].reshape(28, 28)"
      ],
      "metadata": {
        "id": "rEgq4YyrVLjc"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "_z1HzUzHRpEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Procedimiento para hacer la mitad 'missing'\n",
        "half_missing = image.copy()\n",
        "half_width = half_missing.shape[1] // 2\n",
        "half_missing[half_width:, :] = 0  # Hace la mitad derecha 'missing'"
      ],
      "metadata": {
        "id": "B0qCTC4iVZYk"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(half_missing)"
      ],
      "metadata": {
        "id": "qs7rP9J8bWg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "half_missing = half_missing.astype('float32') / 255.\n",
        "half_missing = half_missing.reshape(1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "es7eut5VVQkY"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegurando que 'half_missing' tiene la forma correcta antes de predecir\n",
        "half_missing_flat = half_missing.reshape(1, 28*28)  # Cambia la forma de la imagen a [1, 784]\n",
        "\n",
        "# Ahora pasa la imagen aplanada al autoencoder\n",
        "decoded_img = autoencoder.predict(half_missing_flat)"
      ],
      "metadata": {
        "id": "fwAUJMVhVQgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# Imagen original\n",
        "ax = plt.subplot(1, 3, 1)\n",
        "plt.imshow(image.reshape(28, 28), cmap='gray')\n",
        "ax.set_title(\"Original\")\n",
        "plt.gray()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# Imagen con mitad missing\n",
        "ax = plt.subplot(1, 3, 2)\n",
        "plt.imshow(half_missing.reshape(28, 28), cmap='gray')\n",
        "ax.set_title(\"Half Missing\")\n",
        "plt.gray()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# Imagen reconstruida\n",
        "ax = plt.subplot(1, 3, 3)\n",
        "plt.imshow(decoded_img.reshape(28, 28), cmap='gray')\n",
        "ax.set_title(\"Reconstructed by Autoencoder\")\n",
        "plt.gray()\n",
        "ax.get_xaxis().set_visible(False)\n",
        "ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-b0B03RnVQbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6pT39gytABQ"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GrxhWI6tABR"
      },
      "source": [
        "### Gracias por completar este laboratorio!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXolxax6tABS"
      },
      "source": [
        "### Referencias:\n",
        "- https://en.wikipedia.org/wiki/Autoencoder\n",
        "- http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/\n",
        "- http://www.slideshare.net/billlangjun/simple-introduction-to-autoencoder\n",
        "- http://www.slideshare.net/danieljohnlewis/piotr-mirowski-review-autoencoders-deep-learning-ciuuk14\n",
        "- https://cs.stanford.edu/~quocle/tutorial2.pdf\n",
        "- https://gist.github.com/hussius/1534135a419bb0b957b9\n",
        "- http://www.deeplearningbook.org/contents/autoencoders.html\n",
        "- http://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html/\n",
        "- https://www.youtube.com/watch?v=xTU79Zs4XKY\n",
        "- http://www-personal.umich.edu/~jizhu/jizhu/wuke/Stone-AoS82.pdf"
      ]
    }
  ]
}